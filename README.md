# stockbehavior
Used ML models in order to predict stock behavior

For this project, I wanted to see if I could use previous stock behavior in order to predict whether or not I could predict whether or not a stock will close at higher or lower value than when the market opened. My reasoning was that maybe a machine learning model could pick up on trends that occur in the several days preceding the current day which could provide a probability of whether or not a stock will increase or decrease in price. I decided to keep the stocks I would analyze within the same industry as they would generally be subjected to the same market trends; incorporating other industries could make it harder for my model to pick up on patterns. Thus, I decided to analyze stocks in the tech industry, and chose to analyze Microsoft, Netflix, Apple, Google, Tesla, Meta (Facebook), FactSet Research Systems, Intel, Amazon, Square, Adobe, Twitter, Nvidia, and IBM. Furthermore, I only included data from fiscal year 2019 due to the abnormal volatility in 2020. I was hoping to get its predictions to be correct greater than 50% of the time as that can lead to longterm profits. Finally, I also tested to see how well the model’s predictions would hold after the model recovered in 2020.

The first thing I did was download the the stock prices for the aforementioned companies from Yahoo Finance. I then uploaded the data into techstocks.xlsx and normalized it, as machine learning models work better on data that are of the same magnitude. I then used a MAE (mlstocksmae.py) to predict the stock price, and tested this on various window sizes and architectures. However, the accuracy seemed to hover around 50%. I then realized since I was only predicted the behavior and not the magnitude of the stock changes that I could instead use the BinaryCrossEntropy loss function and treat the problem as a classification problem as opposed to a forecasting problem, which would make it much easier to solve (see mlstocksaccuracy.py).

Next, I determined the best window size. I could either have my windows overlap, i.e. the same time steps be included in different data points, or have them non-overlap, where the same time steps would not be included in different data points. It seemed that while overlapping data included more data points, I was worried that it could lead to overfitting since the same time steps would be used multiple times. However, after testing the different windows on various architectures, it seemed that the overlapping window produced more accurate results than the non-overlapping window.

Afterwards, I set up various models, which are in mlstocksaccuracy.py, and determined their learning rates. I did this by adjusting the learning rates as the models would train and observing which learning rate caused the error to rocket. Finally, I went through the different models to see which one would yield the best predictions. Ultimately, ModelRNN2 over a 10 day window was the most accurate, and achieved a 54% accuracy. When applying this model to the stock market after it crashed in 2020, I was able to again achieve 54% accuracy, suggesting that there are possible patterns that could determine whether or not a stock’s closing price will be higher or lower than its opening.

In the future, I want to see if I can incorporate different architectures, such as LSTMs or CNNs. I also want to train using more data with more companies over a longer time period. I also would like to see what effect the pandemic has had on these patterns, if any, at this point in time. Finally, something weird that I noticed was that the validation data accuracy was sometimes greater than the testing data accuracy, and is something I would like to explore further.
